{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU8f5O1E-pYL"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g0IpFX7_8s7",
        "outputId": "2fa22ebc-4fb0-4079-cf48-a8fef27193c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'modpo'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 164 (delta 67), reused 154 (delta 57), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (164/164), 58.64 KiB | 566.00 KiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf modpo\n",
        "\n",
        "!git clone https://github.com/ZHZisZZ/modpo.git > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conda create -n modpo python=3.10\n",
        "# conda activate modpo\n",
        "# !pip install torch==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "# !pip install -r requirements.txt\n",
        "# # (optional) pip install flash-attn==2.3.2 --no-build-isolation"
      ],
      "metadata": {
        "id": "zSJJUN92mCxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab version for CPU, else modify code above\n",
        "\n",
        "# > /dev/null - to hide messages, but watch warning and errors\n",
        "# !pip install virtualenv > /dev/null\n",
        "# !virtualenv modpo > /dev/null\n",
        "\n",
        "# !source modpo/bin/activate > /dev/null\n",
        "\n",
        "# !pip install torch==2.1.0 --index-url https://download.pytorch.org/whl/cu118 > /dev/null\n",
        "\n",
        "# !pip install -r modpo/requirements.txt > /dev/null\n",
        "\n",
        "# !pip install flash-attn==2.3.2 --no-build-isolation > /dev/null"
      ],
      "metadata": {
        "id": "6uXQnHetmGMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# another collab version for T4\n",
        "\n",
        "!pip uninstall -y torch torchaudio torchvision fsspec gcsfs datasets bigframes trl\n",
        "\n",
        "!pip install torch==2.4.1 torchaudio==2.4.1 torchvision==0.19.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install fsspec==2023.6.0 gcsfs>=2023.3.0\n",
        "\n",
        "!pip install datasets==2.14.5\n",
        "\n",
        "!pip install -r modpo/requirements.txt"
      ],
      "metadata": {
        "id": "pfdYS0btl0ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONPATH=. accelerate launch --config_file scripts/accelerate_configs/multi_gpu.yaml --num_processes=8 \\\n",
        "    scripts/examples/dpo/dpo.py \\\n",
        "    --sft_model_name \"PKU-Alignment/alpaca-7b-reproduced\" \\\n",
        "    --prompt_template \"BEGINNING OF CONVERSATION: USER: {raw_prompt} ASSISTANT:\" \\\n",
        "    --dataset_name \"PKU-Alignment/PKU-SafeRLHF-10K-safer\" \\\n",
        "    --max_length 512 \\\n",
        "    --training_args.output_dir \"./output/PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/safer\" \\\n",
        "    --training_args.run_name \"PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/safer\" \\\n",
        "    --training_args.per_device_train_batch_size 6 \\\n",
        "    --training_args.per_device_eval_batch_size 6 \\\n",
        "    --training_args.gradient_accumulation_steps 2 \\\n",
        "    --training_args.learning_rate 5e-4 \\\n",
        "    --peft_config.r 64 \\\n",
        "    --peft_config.target_modules q_proj k_proj v_proj o_proj \\\n",
        "    --peft_config.lora_alpha 1 \\\n",
        "    --peft_config.lora_dropout 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBjVjXBNGGXs",
        "outputId": "d96c48f4-3680-4779-e1cb-6fb17a407377"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1152, in launch_command\n",
            "    args, defaults, mp_from_config_flag = _validate_launch_command(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 986, in _validate_launch_command\n",
            "    defaults = load_config_from_file(args.config_file)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/config/config_args.py\", line 46, in load_config_from_file\n",
            "    raise FileNotFoundError(\n",
            "FileNotFoundError: The passed configuration file `scripts/accelerate_configs/multi_gpu.yaml` does not exist. Please pass an existing file to `accelerate launch`, or use the default one created through `accelerate config` and run `accelerate launch` without the `--config_file` argument.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiLDLFC4o1IqQtyOmL96Gi"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}