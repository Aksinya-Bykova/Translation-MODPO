{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU8f5O1E-pYL"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq > /dev/null\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6dTjXrk6m0u",
        "outputId": "f4f02174-1446-4058-9e7c-7b34774f3728"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m367121\u001b[0m (\u001b[33mhouse-666\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g0IpFX7_8s7",
        "outputId": "e42c661a-22b7-487c-fe44-6ee6bf21664c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'modpo'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 164 (delta 67), reused 154 (delta 57), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (164/164), 58.64 KiB | 4.51 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf modpo\n",
        "\n",
        "!git clone https://github.com/ZHZisZZ/modpo.git > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conda create -n modpo python=3.10\n",
        "# conda activate modpo\n",
        "# !pip install torch==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "# !pip install -r requirements.txt\n",
        "# # (optional) pip install flash-attn==2.3.2 --no-build-isolation"
      ],
      "metadata": {
        "id": "zSJJUN92mCxm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab version for CPU, else modify code above\n",
        "\n",
        "# > /dev/null - to hide messages, but watch warning and errors\n",
        "# !pip install virtualenv > /dev/null\n",
        "# !virtualenv modpo > /dev/null\n",
        "\n",
        "# !source modpo/bin/activate > /dev/null\n",
        "\n",
        "# !pip install torch==2.1.0 --index-url https://download.pytorch.org/whl/cu118 > /dev/null\n",
        "\n",
        "# !pip install -r modpo/requirements.txt > /dev/null\n",
        "\n",
        "# !pip install flash-attn==2.3.2 --no-build-isolation > /dev/null"
      ],
      "metadata": {
        "id": "6uXQnHetmGMY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# another collab version for T4\n",
        "\n",
        "!pip uninstall -y torch torchaudio torchvision fsspec gcsfs datasets bigframes trl > /dev/null\n",
        "\n",
        "!pip install torch==2.4.1 torchaudio==2.4.1 torchvision==0.19.1 --index-url https://download.pytorch.org/whl/cu121 > /dev/null\n",
        "!pip install fsspec==2023.6.0 gcsfs>=2023.3.0 > /dev/null\n",
        "\n",
        "!pip install datasets==2.14.5 > /dev/null\n",
        "\n",
        "!pip install -r modpo/requirements.txt > /dev/null"
      ],
      "metadata": {
        "id": "pfdYS0btl0ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f230aad3-dc1d-4a58-c10b-bf8242b49abc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping bigframes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение авторской модели"
      ],
      "metadata": {
        "id": "hUr3gP6Xveo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BKf1ZDg8vVaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# os.chdir(\"modpo\")\n",
        "\n",
        "# # modified num_processes: 8 -> 1\n",
        "# # edit your number!\n",
        "# !PYTHONPATH=. accelerate launch --config_file scripts/accelerate_configs/multi_gpu.yaml --num_processes=1 \\\n",
        "#     scripts/examples/dpo/dpo.py \\\n",
        "#     --sft_model_name \"PKU-Alignment/alpaca-7b-reproduced\" \\\n",
        "#     --prompt_template \"BEGINNING OF CONVERSATION: USER: {raw_prompt} ASSISTANT:\" \\\n",
        "#     --dataset_name \"PKU-Alignment/PKU-SafeRLHF-10K-safer\" \\\n",
        "#     --max_length 512 \\\n",
        "#     --training_args.output_dir \"./output/PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/safer\" \\\n",
        "#     --training_args.run_name \"PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/safer\" \\\n",
        "#     --training_args.per_device_train_batch_size 6 \\\n",
        "#     --training_args.per_device_eval_batch_size 6 \\\n",
        "#     --training_args.gradient_accumulation_steps 2 \\\n",
        "#     --training_args.learning_rate 5e-4 \\\n",
        "#     --peft_config.r 64 \\\n",
        "#     --peft_config.target_modules q_proj k_proj v_proj o_proj \\\n",
        "#     --peft_config.lora_alpha 1 \\\n",
        "#     --peft_config.lora_dropout 0"
      ],
      "metadata": {
        "id": "mBjVjXBNGGXs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тест на маленьком датасете и низком качестве гиперпараметров"
      ],
      "metadata": {
        "id": "I6F4Igbc_giQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# cache_dir = os.path.expanduser(\"~/.cache/huggingface/datasets\")\n",
        "# shutil.rmtree(cache_dir)\n",
        "# print(f\"Кэш Hugging Face очищен: {cache_dir}\")"
      ],
      "metadata": {
        "id": "q4S20Hi5BoJ5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Загрузка основного датасета\n",
        "# from datasets import load_dataset\n",
        "\n",
        "# dataset = load_dataset(\"PKU-Alignment/PKU-SafeRLHF-10K\")\n",
        "\n",
        "# print(dataset)"
      ],
      "metadata": {
        "id": "Jp_0eBcfAL29"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_examples = len(dataset[\"train\"])\n",
        "# subset_size = int(num_examples * 0.01)\n",
        "\n",
        "# small_subset = dataset[\"train\"].shuffle(seed=42).select(range(subset_size))\n",
        "\n",
        "# print(small_subset)"
      ],
      "metadata": {
        "id": "RoeyamtGCf1b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"modpo\")\n",
        "\n",
        "!PYTHONPATH=. accelerate launch --config_file scripts/accelerate_configs/multi_gpu.yaml --num_processes=1 \\\n",
        "    scripts/examples/dpo/dpo.py \\\n",
        "    --sft_model_name \"PKU-Alignment/alpaca-7b-reproduced\" \\\n",
        "    --prompt_template \"BEGINNING OF CONVERSATION: USER: {raw_prompt} ASSISTANT:\" \\\n",
        "    --dataset_name \"PKU-Alignment/PKU-SafeRLHF-10K\" \\\n",
        "    --max_length 256 \\\n",
        "    --training_args.output_dir \"./output/PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/safer\" \\\n",
        "    --training_args.run_name \"PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/safer\" \\\n",
        "    --training_args.per_device_train_batch_size 1 \\\n",
        "    --training_args.per_device_eval_batch_size 1 \\\n",
        "    --training_args.gradient_accumulation_steps 1 \\\n",
        "    --training_args.learning_rate 5e-4 \\\n",
        "    --peft_config.r 8 \\\n",
        "    --peft_config.lora_alpha 1 \\\n",
        "    --peft_config.lora_dropout 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9NupaHN9sC6",
        "outputId": "9d167283-cd14-47a4-c83e-56b2e3a7a78c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2024-10-14 14:24:42.972347: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-14 14:24:42.992464: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-14 14:24:42.998669: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-14 14:24:44.817402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tyro/_resolver.py:285: UserWarning: <class 'dict'> does not match any type in Union: [<class 'str'>, <class 'NoneType'>]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tyro/_fields.py:333: UserWarning: The field base_model_name_or_path is annotated with type <class 'str'>, but the default value None has type <class 'NoneType'>. We'll try to handle this gracefully, but it may cause unexpected behavior.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tyro/_fields.py:333: UserWarning: The field revision is annotated with type <class 'str'>, but the default value None has type <class 'NoneType'>. We'll try to handle this gracefully, but it may cause unexpected behavior.\n",
            "  warnings.warn(\n",
            "loading model...\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:437: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "Loading checkpoint shards: 100% 7/7 [01:17<00:00, 11.03s/it]\n",
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(32001, 4096, padding_idx=32000)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
            "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
            "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
            "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
            "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
            "          (act_fn): SiLUActivation()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32001, bias=False)\n",
            ")\n",
            "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=8, target_modules=None, lora_alpha=1, lora_dropout=0.0, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/modpo/scripts/examples/dpo/dpo.py\", line 102, in <module>\n",
            "[rank0]:     rdp = DATASET_CONFIGS[script_args.dataset_name](\n",
            "[rank0]: KeyError: 'PKU-Alignment/PKU-SafeRLHF-10K'\n",
            "[rank0]:[W1014 14:26:05.340218057 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "E1014 14:26:08.207000 135148399136768 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 51921) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 977, in launch_command\n",
            "    multi_gpu_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 646, in multi_gpu_launcher\n",
            "    distrib_run.run(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 892, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "scripts/examples/dpo/dpo.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2024-10-14_14:26:08\n",
            "  host      : 94c4e8d2d453\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 51921)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyML4a/wJQnjtifVNEPB5yk9"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}