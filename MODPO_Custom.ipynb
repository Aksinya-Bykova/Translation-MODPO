{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU8f5O1E-pYL"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq > /dev/null\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6dTjXrk6m0u",
        "outputId": "c46682f1-5139-4f71-a645-8e4defd761cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m367121\u001b[0m (\u001b[33mhouse-666\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g0IpFX7_8s7",
        "outputId": "44762b6b-7859-4f01-f7ed-a254ff88392b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'modpo'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (162/162), done.\u001b[K\n",
            "remote: Total 166 (delta 64), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (166/166), 253.49 KiB | 7.24 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "/content/modpo\n",
            "Cloning into 'modpo'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (162/162), done.\u001b[K\n",
            "remote: Total 166 (delta 64), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (166/166), 253.49 KiB | 5.63 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "/content/modpo/modpo/modpo\n"
          ]
        }
      ],
      "source": [
        "!rm -rf modpo\n",
        "\n",
        "!git clone --branch Develop --single-branch https://github.com/Aksinya-Bykova/Translation-MODPO.git modpo > /dev/null\n",
        "\n",
        "%cd modpo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# another collab version for T4\n",
        "\n",
        "!pip uninstall -y torch torchaudio torchvision fsspec gcsfs datasets bigframes trl > /dev/null\n",
        "\n",
        "!pip install torch==2.4.1 torchaudio==2.4.1 torchvision==0.19.1 --index-url https://download.pytorch.org/whl/cu121 > /dev/null\n",
        "!pip install fsspec==2023.6.0 gcsfs>=2023.3.0 > /dev/null\n",
        "\n",
        "!pip install datasets==2.14.5 > /dev/null\n",
        "\n",
        "!pip install -r modpo/requirements.txt > /dev/null"
      ],
      "metadata": {
        "id": "pfdYS0btl0ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9cf1c1-2b43-42ca-b1f3-2aad9ad3ebd5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping bigframes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping trl as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping bigframes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BKf1ZDg8vVaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тест на низком качестве гиперпараметров"
      ],
      "metadata": {
        "id": "I6F4Igbc_giQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"modpo\")\n",
        "\n",
        "!PYTHONPATH=. accelerate launch --config_file scripts/accelerate_configs/multi_gpu.yaml --num_processes=1 \\\n",
        "    scripts/examples/dpo/dpo.py \\\n",
        "    --sft_model_name \"distilgpt2\" \\\n",
        "    --prompt_template \"BEGINNING OF CONVERSATION: USER: {raw_prompt} ASSISTANT:\" \\\n",
        "    --dataset_name \"marulyanova/PKU-SafeRLHF-10K-Modified\" \\\n",
        "    --max_length 128 \\\n",
        "    --training_args.output_dir \"./output/PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/safer\" \\\n",
        "    --training_args.run_name \"PKU-Alignment/PKU-SafeRLHF-10K/modpo/rm/safer\" \\\n",
        "    --training_args.per_device_train_batch_size 1 \\\n",
        "    --training_args.per_device_eval_batch_size 1 \\\n",
        "    --training_args.gradient_accumulation_steps 1 \\\n",
        "    --training_args.learning_rate 5e-4 \\\n",
        "    --peft_config.r 2 \\\n",
        "    --peft_config.lora_alpha 1 \\\n",
        "    --peft_config.lora_dropout 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9NupaHN9sC6",
        "outputId": "d1e2ca28-fabd-4fab-a800-726f2e76e4da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2024-10-15 14:03:58.706449: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-15 14:03:59.034012: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-15 14:03:59.124911: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-15 14:04:01.606360: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
            "  warnings.warn(\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/modpo/modpo/scripts/examples/dpo/dpo.py\", line 12, in <module>\n",
            "[rank0]:     from src.data.configs import DATASET_CONFIGS, DEFAULT_PROMPT_TEMPLATE\n",
            "[rank0]:   File \"/content/modpo/modpo/src/data/configs.py\", line 59, in <module>\n",
            "[rank0]:     DATASET_CONFIGS = {**REAL_DATASET_CONFIGS, **SYNTHETIC_DATASET_CONFIGS}\n",
            "[rank0]: NameError: name 'SYNTHETIC_DATASET_CONFIGS' is not defined. Did you mean: 'REAL_DATASET_CONFIGS'?\n",
            "[rank0]:[W1015 14:04:03.941488943 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "E1015 14:04:06.656000 133375328129664 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 4218) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 977, in launch_command\n",
            "    multi_gpu_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 646, in multi_gpu_launcher\n",
            "    distrib_run.run(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 892, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "scripts/examples/dpo/dpo.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2024-10-15_14:04:06\n",
            "  host      : db51b87e846a\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 4218)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "2024-10-15 14:05:09.722995: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-15 14:05:09.742577: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-15 14:05:09.748699: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-15 14:05:11.170122: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
            "  warnings.warn(\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/modpo/modpo/modpo/modpo/scripts/examples/dpo/dpo.py\", line 12, in <module>\n",
            "[rank0]:     from src.data.configs import DATASET_CONFIGS, DEFAULT_PROMPT_TEMPLATE\n",
            "[rank0]:   File \"/content/modpo/modpo/modpo/modpo/src/data/configs.py\", line 59, in <module>\n",
            "[rank0]:     DATASET_CONFIGS = {**REAL_DATASET_CONFIGS, **SYNTHETIC_DATASET_CONFIGS}\n",
            "[rank0]: NameError: name 'SYNTHETIC_DATASET_CONFIGS' is not defined. Did you mean: 'REAL_DATASET_CONFIGS'?\n",
            "[rank0]:[W1015 14:05:13.576563388 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "E1015 14:05:19.328000 137982739591808 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 4640) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 977, in launch_command\n",
            "    multi_gpu_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 646, in multi_gpu_launcher\n",
            "    distrib_run.run(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 892, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "scripts/examples/dpo/dpo.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2024-10-15_14:05:19\n",
            "  host      : db51b87e846a\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 4640)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}